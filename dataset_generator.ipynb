{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqIU8uXn0S+DfgJ+sghpz8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Dataset generator (Meta-Llama-3.1-8B-Instruct model)"],"metadata":{"id":"hk8kMxRJMPRT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kU2JrcPlhwd9"},"outputs":[],"source":["#lib install\n","!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate gradio"]},{"cell_type":"markdown","metadata":{"id":"lAMIVT4iwNg0"},"source":["**Imports**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Apd7-p-hyLk"},"outputs":[],"source":["#imports\n","import os\n","import requests\n","from google.colab import drive\n","from huggingface_hub import login\n","from google.colab import userdata\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n","import torch\n","import gradio as gr\n","\n","hf_token = userdata.get('HF_TOKEN')\n","login(hf_token, add_to_git_credential=True)"]},{"cell_type":"markdown","metadata":{"id":"xa0qYqZrwQ66"},"source":["**Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5enGmuKjtJu"},"outputs":[],"source":["#loading quantized model\n","model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n","quant_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_quant_type=\"nf4\"\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","  model_name,\n","  device_map=\"auto\",\n","  quantization_config=quant_config\n",")"]},{"cell_type":"markdown","metadata":{"id":"y1hUSmWlwSbp"},"source":["**Tokenizer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjxNWW6bvdgj"},"outputs":[],"source":["#loading tokenizer to model\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"markdown","metadata":{"id":"1pg2U-B3wbIK"},"source":["**Functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvljDKdji8iV"},"outputs":[],"source":["\n","#generation dataset function\n","def generate_dataset(topic, number_of_data, inst1, resp1, inst2, resp2, inst3, resp3):\n","    # Convert user inputs into multi-shot examples\n","    multi_shot_examples = [\n","        {\"instruction\": inst1, \"response\": resp1},\n","        {\"instruction\": inst2, \"response\": resp2},\n","        {\"instruction\": inst3, \"response\": resp3}\n","    ]\n","\n","    # System prompt\n","    system_prompt = f\"\"\"\n","    You are a helpful assistant whose main purpose is to generate datasets.\n","    Topic: {topic}\n","    Return the dataset in JSON format. Use examples with simple, and easy-to-understand instructions for basic understanding of provided topic.\n","    Include the following examples: {multi_shot_examples}\n","    Return {number_of_data} examples each time.\n","    Do not repeat the provided examples.\n","    \"\"\"\n","\n","    # Example Messages\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": f\"Please generate my dataset for {topic}\"}\n","    ]\n","\n","    # Tokenize Input\n","    inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n","    streamer = TextStreamer(tokenizer)\n","\n","    # Generate Output\n","    outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)\n","\n","    # Decode and Return\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","\n","def gradio_interface(topic, number_of_data, inst1, resp1, inst2, resp2, inst3, resp3):\n","    return generate_dataset(topic, number_of_data, inst1, resp1, inst2, resp2, inst3, resp3)"]},{"cell_type":"code","source":["#Fixing system_promt returning as part of the output\n","\n","def generate_dataset2(topic, number_of_data, inst1, resp1, inst2, resp2, inst3, resp3):\n","    # Multi-shot examples como texto plano\n","    example_text = f\"\"\"\n","Examples:\n","Instruction: {inst1}\n","Response: {resp1}\n","\n","Instruction: {inst2}\n","Response: {resp2}\n","\n","Instruction: {inst3}\n","Response: {resp3}\n","\"\"\"\n","\n","    # Prompt plano (estilo instrucional)\n","    prompt = f\"\"\"You are a helpful assistant that generates simple JSON datasets.\n","Topic: {topic}\n","Your goal is to generate {number_of_data} new instruction-response examples in JSON format.\n","Use clear and easy-to-understand language.\n","Do not repeat the examples already given.\n","\n","{example_text}\n","\n","Now generate the dataset:\n","\"\"\"\n","\n","    # Tokeniza sem usar chat_template\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","    streamer = TextStreamer(tokenizer)\n","\n","    # Gera a resposta\n","    outputs = model.generate(inputs[\"input_ids\"], max_new_tokens=2000, streamer=streamer)\n","\n","    # Decodifica\n","    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","    # Tenta remover o prompt do começo, se repetido\n","    cleaned_output = output_text.replace(prompt.strip(), \"\").strip()\n","\n","    return cleaned_output\n","\n","def gradio_interface2(topic, number_of_data, inst1, resp1, inst2, resp2, inst3, resp3):\n","    return generate_dataset2(topic, number_of_data, inst1, resp1, inst2, resp2, inst3, resp3)\n"],"metadata":{"id":"ZquaeyVgK09o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_WDZ5dvRwmng"},"source":["**Default Values**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JAdfqYXnvEDE"},"outputs":[],"source":["default_topic = \"Explaining basic financial concepts to beginners\"\n","default_number_of_data = 10\n","default_multi_shot_examples = [\n","    {\n","        \"instruction\": \"What is a budget?\",\n","        \"response\": \"A budget is a simple plan to help you decide how to spend your money so you don’t run out.\"\n","    },\n","    {\n","        \"instruction\": \"Why is saving money important?\",\n","        \"response\": \"Saving money helps you buy things later or handle emergencies without stress.\"\n","    },\n","    {\n","        \"instruction\": \"What does interest mean in finance?\",\n","        \"response\": \"Interest is extra money you earn when you save, or extra money you pay when you borrow.\"\n","    }\n","]"]},{"cell_type":"markdown","metadata":{"id":"JwZtD032wuK8"},"source":["**Init gradio**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xy2RP5T-vxXg"},"outputs":[],"source":["gr_interface = gr.Interface(\n","    fn=gradio_interface2,\n","    inputs=[\n","        gr.Textbox(label=\"Topic\", value=default_topic, lines=2),\n","        gr.Number(label=\"Number of Examples\", value=default_number_of_data, precision=0),\n","        gr.Textbox(label=\"Instruction 1\", value=default_multi_shot_examples[0][\"instruction\"]),\n","        gr.Textbox(label=\"Response 1\", value=default_multi_shot_examples[0][\"response\"]),\n","        gr.Textbox(label=\"Instruction 2\", value=default_multi_shot_examples[1][\"instruction\"]),\n","        gr.Textbox(label=\"Response 2\", value=default_multi_shot_examples[1][\"response\"]),\n","        gr.Textbox(label=\"Instruction 3\", value=default_multi_shot_examples[2][\"instruction\"]),\n","        gr.Textbox(label=\"Response 3\", value=default_multi_shot_examples[2][\"response\"]),\n","    ],\n","    outputs=gr.Textbox(label=\"Generated Dataset\")\n",")"]},{"cell_type":"markdown","metadata":{"id":"HZx-mm9Uw3Ph"},"source":["**Run the app**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfGs5ip8mndg"},"outputs":[],"source":["gr_interface.launch()"]}]}